{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the first-level results\n",
    "\n",
    "After running our GLM analysis, we have the estimated amplitude responses of each voxel to each image class. Along with Noah Benson's anatomical template / Bayesian model, we also have each voxel's visual area and location in the visual field (in terms of eccentricity and polar angle). By combining the information contained within them, along with the dataframe describing each stimulus class, we can construct our tuning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import sfp\n",
    "import h5py\n",
    "import os\n",
    "import itertools\n",
    "import pyPyrTools.JBhelpers as jbh\n",
    "import pyPyrTools as ppt\n",
    "import scipy as sp\n",
    "from matplotlib.colors import LinearSegmentedColormap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains the button presses (which also show the TR onsets) \n",
    "# and the order the stimuli were presented in (along with their timing)\n",
    "behav_results = h5py.File('../data/raw_behavioral/2017-Nov-07_wl_subj042_sess0.hdf5')\n",
    "#behav_results = h5py.File('../data/raw_behavioral/2017-Nov-07_wl_subj045_sess0.hdf5')\n",
    "#behav_results = h5py.File('../data/raw_behavioral/2017-Oct-09_wl_subj001_sess1.hdf5')\n",
    "\n",
    "# This contains the information on each stimulus, allowing us to determine whether\n",
    "# some stimuli are part of the same class or a separate one.\n",
    "stim_df = pd.read_csv(\"../data/stimuli/unshuffled_stim_description.csv\", index_col=0)\n",
    "\n",
    "# Array full of the actual stimuli\n",
    "stim = np.load('../data/stimuli/unshuffled.npy')\n",
    "\n",
    "# for this, we just want any run, since they all contain the same classes and we don't care about their order\n",
    "design_df, _, _ = sfp.design_matrices.create_design_df(behav_results, stim_df, 1)\n",
    "design_df = design_df.reset_index(drop=True).sort_values(by=\"class_idx\")\n",
    "design_df = design_df[['w_r', 'w_a', 'class_idx', 'alpha', 'res']].set_index('class_idx')\n",
    "\n",
    "stim_df = stim_df.set_index(['w_r', 'w_a'])\n",
    "stim_df['class_idx'] = design_df.reset_index().set_index(['w_r', 'w_a'])['class_idx']\n",
    "stim_df = stim_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/billbrod/Desktop/wl_subj001_bootstrapped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name = 'wl_subj001'\n",
    "benson_path = \"%s/%s/surf/{}.benson14_{}.mgz\" % (os.environ['SUBJECTS_DIR'], subject_name)\n",
    "results_path = \"/mnt/Acadia/Projects/spatial_frequency_preferences/%s/20171007_prisma/MRI_first_level/results/stim_class/{}-{}.mgz\" % subject_name\n",
    "benson_path = benson_path.replace('{}', '%s')\n",
    "results_path = results_path.replace('{}', '%s')\n",
    "\n",
    "df = sfp.first_level_analysis.create_GLM_result_df(design_df, benson_path, results_path, 'full', '/home/billbrod/Desktop/wl_subj001_bootstrapped.csv', vareas=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name = 'wl_subj042'\n",
    "benson_path = \"%s/%s/surf/{}.benson14_{}.mgz\" % (os.environ['SUBJECTS_DIR'], subject_name)\n",
    "results_path = \"/mnt/Acadia/Projects/spatial_frequency_preferences/%s/20171107/MRI_first_level/stim_class/results/{}-{}.mgz\" % subject_name\n",
    "benson_path = benson_path.replace('{}', '%s')\n",
    "results_path = results_path.replace('{}', '%s')\n",
    "\n",
    "df = sfp.first_level_analysis.create_GLM_result_df(design_df, benson_path, results_path, 'full', eccen_bin=True, vareas=[1,2], class_nums=[11, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name = 'wl_subj045'\n",
    "# benson_path = \"%s/%s/surf/{}.benson14_{}.mgz\" % (os.environ['SUBJECTS_DIR'], subject_name)\n",
    "benson_path = \"%s/%s/surf/{}.template_{}.mgz\" % (os.environ['SUBJECTS_DIR'], subject_natme)\n",
    "results_path = \"/mnt/Acadia/Projects/spatial_frequency_preferences/%s/20171107/MRI_first_level/stim_class/results/{}-{}.mgz\" % subject_name\n",
    "benson_path = benson_path.replace('{}', '%s')\n",
    "results_path = results_path.replace('{}', '%s')\n",
    "\n",
    "df = sfp.first_level_analysis.create_GLM_result_df(design_df, benson_path, results_path, 'summary', vareas=[1,2], eccen_bin=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the different stimulus classes, as plotted in frequency space, colored by their superclass. These numbers are roughly log-spaced (doubling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    g = sns.FacetGrid(df[df.voxel==0], hue='stimulus_superclass', size=5, aspect=1)\n",
    "    g.ax.plot([-150, 200], [0,0],'k--', alpha=.5)\n",
    "    g.ax.plot([0, 0], [-100, 250], 'k--', alpha=.5)\n",
    "    g.map(sns.plt.scatter, 'w_a', 'w_r')\n",
    "    g.add_legend()\n",
    "    _=g.ax.axis('equal')\n",
    "    g.ax.set_xlim([-150, 200])\n",
    "    g.ax.set_ylim([-100, 250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sin(size, w_x, w_y, origin=None):\n",
    "    if origin is None:\n",
    "        origin = ((size+1)/2., (size+1)/2.)\n",
    "    x, y = np.meshgrid(np.array(range(1, size+1))-origin[0], \n",
    "                       np.array(range(1, size+1))-origin[1])\n",
    "    return np.cos(x*w_x + y*w_y)\n",
    "\n",
    "size = 1000\n",
    "masked_stim = np.zeros((size, size))\n",
    "masked_grad = np.zeros((size, size))\n",
    "w_x = .05\n",
    "w_y = .05\n",
    "tmp_stim = create_sin(size, w_x, w_y)\n",
    "dx = w_x * np.ones((size, size))\n",
    "dy = w_y * np.ones((size, size))\n",
    "for i in range(0, size+3, 99):\n",
    "    for j in range(0, size+3, 99):\n",
    "        loc_x, loc_y = i,j\n",
    "        mask = sfp.utils.create_circle_mask(loc_x, loc_y, 48, size)\n",
    "        masked_stim += mask*tmp_stim\n",
    "        masked_grad += mask*calc_grad_sin(dx, dy, loc_x, loc_y)[0]\n",
    "jbh.showIm([masked_stim, masked_grad], ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sf_maps(size, alpha, w_r, w_a, origin=None):\n",
    "    if origin is None:\n",
    "        origin = ((size+1)/2., (size+1)/2.)\n",
    "    x, y = np.meshgrid(np.array(range(1, size+1))-origin[0], \n",
    "                       np.array(range(1, size+1))-origin[1])\n",
    "    dy = (2*y*(w_r/np.pi)) / ((x**2 + y**2 + alpha**2)*np.log(2)) + w_a / ((1 + (y/x)**2) * x)\n",
    "    dx = (2*x*(w_r/np.pi)) / ((x**2 + y**2 + alpha**2)*np.log(2)) - (w_a * y) / ((1 + (y/x)**2) * x**2)\n",
    "    return dx, dy\n",
    "\n",
    "def calc_grad_sin_constant(dx, dy, loc_x, loc_y, alpha=50, phase=0, origin=None):\n",
    "    size = dx.shape[0]\n",
    "    x, y = np.meshgrid(np.array(range(1, size+1))-loc_x, \n",
    "                       np.array(range(1, size+1))-loc_y)\n",
    "    if origin is None:\n",
    "        origin = ((size+1)/2., (size+1)/2.)\n",
    "    x_orig, y_orig = np.meshgrid(np.array(range(1, size+1))-origin[0], \n",
    "                       np.array(range(1, size+1))-origin[1])\n",
    "    w_x = dx[loc_y, loc_x]\n",
    "    w_y = dy[loc_y, loc_x]\n",
    "    local_phase = np.mod(w_x*x_orig[loc_y, loc_x] + w_y*y_orig[loc_y, loc_x] + phase, 2*np.pi)\n",
    "    return np.cos(w_x*x + w_y*y + local_phase), local_phase\n",
    "\n",
    "def calc_grad_sin_polar(dx, dy, loc_x, loc_y, w_r, w_a, alpha=50, phase=0, origin=None):\n",
    "    size = dx.shape[0]\n",
    "    x, y = np.meshgrid(np.array(range(1, size+1))-loc_x, \n",
    "                       np.array(range(1, size+1))-loc_y)\n",
    "    if origin is None:\n",
    "        origin = ((size+1)/2., (size+1)/2.)\n",
    "    x_orig, y_orig = np.meshgrid(np.array(range(1, size+1))-origin[0], \n",
    "                       np.array(range(1, size+1))-origin[1])\n",
    "    local_x = x_orig[loc_y, loc_x]\n",
    "    local_y = y_orig[loc_y, loc_x]\n",
    "    w_x = dx[loc_y, loc_x]\n",
    "    w_y = dy[loc_y, loc_x]\n",
    "    local_phase = np.mod((w_r/np.pi)*np.log2(local_x**2 + local_y**2+alpha**2)+ w_a*np.arctan2(local_y,local_x) + phase, 2*np.pi)\n",
    "    if w_x==0 and w_y==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.cos(w_x*x + w_y*y + local_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=2\n",
    "\n",
    "def create_sin(size, w_x, w_y, origin=None):\n",
    "    if origin is None:\n",
    "        origin = ((size+1)/2., (size+1)/2.)\n",
    "    x, y = np.meshgrid(np.array(range(1, size+1))-origin[0], \n",
    "                       np.array(range(1, size+1))-origin[1])\n",
    "    return np.cos(x*w_x + y*w_y)\n",
    "\n",
    "size = 1080\n",
    "phases = np.zeros((len(range(0, size+3, 99)), len(range(0, size+3, 99))))\n",
    "masked_stim = np.zeros((size, size))\n",
    "masked_grad = np.zeros((size, size))\n",
    "for i, loc_x in enumerate(range(0, size+3, 99)):\n",
    "    for j, loc_y in  enumerate(range(0, size+3, 99)):\n",
    "        mask = sfp.utils.create_circle_mask(loc_x, loc_y, 48, size)\n",
    "        x, y = np.meshgrid(np.array(range(1, size+1)) - loc_x,\n",
    "                           np.array(range(1, size+1))- loc_y)\n",
    "        w_x = dxs[idx][loc_y, loc_x]\n",
    "        w_y = dys[idx][loc_y][loc_x]\n",
    "        def opt_sin((x,y), phase):\n",
    "            return (mask*np.cos(w_x * x + w_y * y + phase)).ravel()\n",
    "        popt, pcov = sp.optimize.curve_fit(opt_sin, (x,y), (mask*tmp_stims[idx]).ravel(), bounds=(0, 2*np.pi))\n",
    "        phases[i, j] = popt[0]\n",
    "        masked_stim += mask * tmp_stims[idx]\n",
    "        masked_grad += opt_sin((x,y), popt[0]).reshape((size, size))\n",
    "\n",
    "jbh.showIm([masked_stim, masked_grad], ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=2\n",
    "masked_stim = np.zeros((1080, 1080))\n",
    "masked_grad = np.zeros((1080,1080))\n",
    "masked_pol = np.zeros((1080,1080))\n",
    "w_r = stim_df[stim_df.index==stim_idx[idx]].w_r.unique()[0]\n",
    "w_a = stim_df[stim_df.index==stim_idx[idx]].w_a.unique()[0]\n",
    "masks = np.zeros((1080, 1080))\n",
    "for i, loc_x in enumerate(range(50, 1080, 99)):\n",
    "    for j, loc_y in enumerate(range(50, 1080, 99)):\n",
    "        mask = sfp.utils.create_circle_mask(loc_x, loc_y, 48, 1080)\n",
    "        masks += mask\n",
    "        masked_stim += mask*tmp_stims[idx]\n",
    "        local_grad = calc_grad_sin_polar(dxs[idx], dys[idx], loc_x, loc_y, w_r, w_a)\n",
    "        masked_grad += mask*local_grad\n",
    "masked_grad[~masks.astype(bool)] -= 1\n",
    "jbh.showIm([masked_stim, masked_grad], ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "masked_stim = np.zeros((1080, 1080))\n",
    "masked_grad = np.zeros((1080,1080))\n",
    "masked_pol = np.zeros((1080,1080))\n",
    "w_r = stim_df[stim_df.index==stim_idx[idx]].w_r.unique()[0]\n",
    "w_a = stim_df[stim_df.index==stim_idx[idx]].w_a.unique()[0]\n",
    "masks = np.zeros((1080,1080))\n",
    "for i in range(27, 1080, 55):\n",
    "    for j in range(27, 1080, 55):\n",
    "        loc_x, loc_y = i, j\n",
    "        mask = sfp.utils.create_circle_mask(loc_x, loc_y, 27, 1080)\n",
    "        masks += mask\n",
    "        masked_stim += mask*tmp_stims[idx]\n",
    "        #masked_pol += mask*calc_grad_sin_polar(mags[idx], direcs[idx], loc_x, loc_y)\n",
    "        masked_grad += mask*calc_grad_sin_polar(dxs[idx], dys[idx], loc_x, loc_y, w_r, w_a)\n",
    "masked_grad[~masks.astype(bool)] -= 1\n",
    "jbh.showIm([masked_stim, masked_grad], ncols=3)\n",
    "#jbh.showIm([tmp_stims[idx], gradient_sin, polar_sin], ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=1\n",
    "masked_stim = np.zeros((1080, 1080))\n",
    "masked_grad = np.zeros((1080,1080))\n",
    "masked_pol = np.zeros((1080,1080))\n",
    "w_r = stim_df[stim_df.index==stim_idx[idx]].w_r.unique()[0]\n",
    "w_a = stim_df[stim_df.index==stim_idx[idx]].w_a.unique()[0]\n",
    "masks = np.zeros((1080, 1080))\n",
    "for i in range(50, 1080, 99):\n",
    "    for j in range(50, 1080, 99):\n",
    "        loc_x, loc_y = i, j\n",
    "        mask = sfp.utils.create_circle_mask(loc_x, loc_y, 48, 1080)\n",
    "        masks += mask\n",
    "        masked_stim += mask*tmp_stims[idx]\n",
    "        #masked_pol += mask*calc_grad_sin_polar(mags[idx], direcs[idx], loc_x, loc_y)\n",
    "        masked_grad += mask*calc_grad_sin_polar(dxs[idx], dys[idx], loc_x, loc_y, w_r, w_a)\n",
    "masked_grad[~masks.astype(bool)] -= 1\n",
    "jbh.showIm([masked_stim, masked_grad], ncols=3)\n",
    "#jbh.showIm([tmp_stims[idx], gradient_sin, polar_sin], ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = []\n",
    "direcs = []\n",
    "stim_idx = [stim_df[(stim_df.w_r==181)&(stim_df.w_a==0)].index.values[0]]\n",
    "stim_idx.append(stim_df[(stim_df.w_r==0)&(stim_df.w_a==181)].index.values[0])\n",
    "stim_idx.append(stim_df[(stim_df.w_r==128)&(stim_df.w_a==128)].index.values[0])\n",
    "tmp_stims = []\n",
    "dxs, dys= [], []\n",
    "for i in range(3):\n",
    "    a_stim = stim[stim_idx[i],:,:]\n",
    "    tmp_stims.append(a_stim)\n",
    "    w_r = stim_df[stim_df.index==stim_idx[i]].w_r.values[0]\n",
    "    w_a = stim_df[stim_df.index==stim_idx[i]].w_a.values[0]\n",
    "    alpha = stim_df[stim_df.index==stim_idx[i]].alpha.values[0]\n",
    "    R = ppt.mkR(a_stim.shape)\n",
    "    x, y = np.where(a_stim!=127)\n",
    "    Rmin, Rmax = R[x,y].min(), R[x,y].max()\n",
    "    dx, dy = calc_sf_maps(1080, alpha, w_r, w_a)\n",
    "    dxs.append(dx)\n",
    "    dys.append(dy)\n",
    "    direc = np.arctan2(dy, dx)\n",
    "    mag = np.sqrt(dx**2 + dy**2)\n",
    "    mags.append(mag)\n",
    "    direcs.append(direc)\n",
    "    dx[R<Rmin] = 0\n",
    "    dx[R>Rmax] = 0\n",
    "    dy[R<Rmin] = 0\n",
    "    dy[R>Rmax] = 0\n",
    "    mag[R<Rmin] = 0\n",
    "    mag[R>Rmax] = 0\n",
    "    direc[R<Rmin] = 0\n",
    "    direc[R>Rmax] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([j for i in zip(tmp_stims[:2], mags[:2], direcs[:2]) for j in i], ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([j for i in zip(tmp_stims[2:], mags[2:], direcs[2:]) for j in i], ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([j for i in zip(tmp_stims[2:], mags[2:], direcs[2:]) for j in i], ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags[1][540,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags[1][540,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['circular', 'radial', 'spiral']\n",
    "sns.plt.figure(figsize=(15,5))\n",
    "sns.plt.subplot(121)\n",
    "for i in range(3):\n",
    "    sns.plt.plot(np.array(range(1080))-540.5, mags[i][540,:], label=names[i])\n",
    "sns.plt.legend()\n",
    "# sns.plt.subplot(122)\n",
    "# for i in range(3):\n",
    "#     sns.plt.plot(np.array(range(1080))-540.5, direcs[i][540,:]/np.pi, label=names[i])\n",
    "# sns.plt.ylabel('Fraction of $\\pi$')\n",
    "# sns.plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['circular', 'radial', 'spiral']\n",
    "sns.plt.figure(figsize=(15,5))\n",
    "sns.plt.subplot(121)\n",
    "sns.plt.plot(np.array(range(1080))-540.5, mags[0][540,:]/mags[0][540,:], label=names[0])\n",
    "sns.plt.plot(np.array(range(1080))-540.5, mags[1][540,:]/mags[0][540,:], label=names[1])\n",
    "sns.plt.plot(np.array(range(1080))-540.5, mags[2][540,:]/mags[0][540,:], label=names[2])\n",
    "sns.plt.legend()\n",
    "# sns.plt.subplot(122)\n",
    "# for i in range(3):\n",
    "#     sns.plt.plot(np.array(range(1080))-540.5, direcs[i][540,:]/np.pi, label=names[i])\n",
    "# sns.plt.ylabel('Fraction of $\\pi$')\n",
    "# sns.plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmin, Rmax = sfp.first_level_analysis.find_ecc_range_in_degrees(stim[0,:,:], 12)\n",
    "print(\"Inside radius of stimulus annulus: %.02f\" % Rmin)\n",
    "print(\"Outside radius of stimulus annulus: %.02f\" % Rmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df[df.stimulus_superclass=='circular']\n",
    "g = sns.FacetGrid(df, hue='eccen', palette='Reds', size=5,)\n",
    "#g.map(sns.regplot, 'rounded_freq_space_distance', 'amplitude_estimate', x_estimator=np.mean, fit_reg=False)\n",
    "g.map_dataframe(sfp.utils.plot_mean, 'rounded_freq_space_distance', 'amplitude_estimate')\n",
    "g.map_dataframe(sfp.utils.scatter_ci_dist, 'freq_space_distance', 'amplitude_estimate')\n",
    "for ax in g.axes.flatten():\n",
    "    ax.set_xscale('log', basex=2)\n",
    "g.add_legend()\n",
    "g.fig.savefig('wl_subj042-raw.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, hue='eccen', palette='Reds', size=5, col='stimulus_superclass', col_wrap=2,\n",
    "                  col_order=['circular', 'radial', 'forward spiral', 'reverse spiral', 'mixtures'])\n",
    "#g.map(sns.regplot, 'freq_space_distance', 'amplitude_estimate', x_estimator=np.mean, fit_reg=False)\n",
    "g.map_dataframe(sfp.utils.plot_mean, 'freq_space_distance', 'amplitude_estimate')\n",
    "g.map_dataframe(sfp.utils.scatter_ci_dist, 'freq_space_distance', 'amplitude_estimate')\n",
    "for ax in g.axes:\n",
    "    ax.set_xscale('log', basex=2)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there were no scaling in the visual system, such that neurons at different places in the visual field were expected to have similar properties, the bottom would all line up well, and it doesn't!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_of_interest = []\n",
    "classes_of_interest.extend(df[(df.stimulus_superclass=='circular')&(df.rounded_freq_space_distance==11)].stimulus_class.unique())\n",
    "classes_of_interest.extend(df[(df.stimulus_superclass=='radial')&(df.rounded_freq_space_distance==64)].stimulus_class.unique())\n",
    "classes_of_interest.extend(df[(df.stimulus_superclass=='forward spiral')&(df.rounded_freq_space_distance==23)].stimulus_class.unique())\n",
    "classes_of_interest.extend(df[(df.stimulus_superclass=='reverse spiral')&(df.rounded_freq_space_distance==23)].stimulus_class.unique())\n",
    "#classes_of_interest.append(df[df.stimulus_superclass=='mixtures'].stimulus_class.values[0])\n",
    "\n",
    "stim_idxs = stim_df[stim_df.class_idx.isin(classes_of_interest)].index.values[::8]\n",
    "\n",
    "jbh.showIm([stim[i, :, :] for i in stim_idxs], ncols=4, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I know this goes from about -pi/2 to pi/2, in pi/12 steps\n",
    "ticks = [(np.pi*(i-6)/12.) for i in range(13)]\n",
    "labels = ['$\\\\frac{%s*\\\\pi}{12}$'%(i-6) for i in range(13)]\n",
    "\n",
    "g = sns.FacetGrid(df, hue='eccen', palette='Reds', size=6)\n",
    "g.map(sns.regplot, 'freq_space_angle', 'amplitude_estimate', x_estimator=np.mean, fit_reg=False)\n",
    "g.map_dataframe(sfp.utils.plot_mean, 'freq_space_angle', 'amplitude_estimate')\n",
    "#g.map_dataframe(sfp.utils.scatter_ci, 'freq_space_angle', 'amplitude_estimate_median', 'amplitude_estimate_std_error') \n",
    "_=g.ax.set_xticks(ticks)\n",
    "_=g.ax.set_xticklabels(labels)\n",
    "g.add_legend()\n",
    "\n",
    "# I know this goes from about -pi/2 to pi/2, in pi/12 steps\n",
    "ticks = [(np.pi*(i-6)/12.) for i in range(13)]\n",
    "labels = ['$\\\\frac{%s*\\\\pi}{12}$'%(i-6) for i in range(13)]\n",
    "\n",
    "tmp_df = df[df.stimulus_superclass=='mixtures']\n",
    "g = sns.FacetGrid(tmp_df, hue='eccen', palette='Reds', size=6)\n",
    "g.map(sns.regplot, 'freq_space_angle', 'amplitude_estimate', x_estimator=np.mean, fit_reg=False)\n",
    "g.map_dataframe(sfp.utils.plot_mean, 'freq_space_angle', 'amplitude_estimate')\n",
    "#g.map_dataframe(sfp.utils.scatter_ci, 'freq_space_angle', 'amplitude_estimate_median', 'amplitude_estimate_std_error') \n",
    "_=g.ax.set_xticks(ticks)\n",
    "_=g.ax.set_xticklabels(labels)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = sorted(df.freq_space_angle.unique())\n",
    "stim_idxs = []\n",
    "for ang in angles:\n",
    "    class_of_interest = df[(df.freq_space_angle==ang)&(df.rounded_freq_space_distance==32)].stimulus_class.unique()[0]\n",
    "    stim_idxs.append(stim_df[stim_df.class_idx==class_of_interest].index[0])\n",
    "\n",
    "#stim_idxs = stim_df[stim_df.class_idx.isin(classes_of_interest)].index.values[::8]\n",
    "\n",
    "jbh.showIm([stim[i, :, :] for i in stim_idxs], ncols=4, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame(df.groupby(['eccen_bin', 'w_r', 'w_a']).modelmd.mean()).reset_index()\n",
    "\n",
    "g = sns.FacetGrid(tmp_df, col='eccen_bin', col_wrap=4, size=5)\n",
    "cbar_ax = g.fig.add_axes([.92, .3, .02, .4])  # <-- Create a colorbar axes\n",
    "g.map(sfp.utils.scatter_heat, 'w_a', 'w_r', 'amplitude_estimate_median', vmin=tmp_df['amplitude_estimate_median'].min(), \n",
    "      vmax=tmp_df['amplitude_estimate_median'].max())\n",
    "sns.plt.colorbar(cax=cbar_ax)\n",
    "g.fig.subplots_adjust(right=.9, top=.9)\n",
    "g.fig.suptitle('Average response amplitude estimates at each point in frequency space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.pivot_table(df, 'amplitude_estimate_median', 'rounded_freq_space_distance', 'eccen_bin')\n",
    "norm_df = tmp_df.copy()\n",
    "for col in norm_df.columns:\n",
    "    norm_df[col] = norm_df[col] / norm_df[col].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.heatmap(tmp_df, cmap='Reds')\n",
    "fig.invert_yaxis()\n",
    "fig.set_title('Average response amplitude estimates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.heatmap(norm_df, cmap='Reds')\n",
    "fig.invert_yaxis()\n",
    "fig.set_title('Normalized average response amplitude estimates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.R2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create plots for first year talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this, we're only using circular results\n",
    "tmp_df = df[df.stimulus_superclass=='circular']\n",
    "# tmp_df = tmp_df[['eccen', 'amplitude_estimate', 'freq_space_distance', 'Local spatial frequency (cpd)', 'bootstrap_num', 'hemi']]\n",
    "tmp_df = tmp_df[['eccen', 'amplitude_estimate', 'freq_space_distance', 'Local spatial frequency (cpd)', 'bootstrap_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmper_df = tmp_df[tmp_df.freq_space_distance==6.]\n",
    "tmper_df = tmper_df.groupby(['eccen', 'bootstrap_num'])['amplitude_estimate'].mean().unstack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_df = pd.melt(tmp_df, ['eccen', 'amplitude_estimate', 'bootstrap_num'], var_name='Frequency')\n",
    "hyp_df = pd.DataFrame(hyp_df.groupby(['Frequency', 'value', 'bootstrap_num'])['amplitude_estimate'].mean()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"freq_space_distance min: %.03f, max: %.03f\" % (tmp_df.freq_space_distance.min(), tmp_df.freq_space_distance.max()))\n",
    "print(\"Halfway in log space: %.03f\" % np.floor(2**((np.log2(181.) + np.log2(6.))/2.)))\n",
    "# because these are circular, freq_space_distance==w_r\n",
    "#stim_idx = stim_df[(stim_df.w_r.isin([6, 32, 181]))&(stim_df.w_a==0)].index[::8]\n",
    "stim_idx = stim_df[(stim_df.w_r.isin([6, 32, ]))&(stim_df.w_a==0)].index[::8]\n",
    "stims = [stim[i] for i in stim_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually want to plot windows of the stimuli instead of just sins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree_rad = 12\n",
    "scale_factor = 10\n",
    "mask = sfp.utils.create_circle_mask(750, 350, scale_factor* 1080/(2*2*max_degree_rad), 1080)\n",
    "stim_windows = [mask * s + ~mask.astype(bool)*127 for s in stims]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def fit_log_norm_ci(x, y, ci_vals=[2.5, 97.5], **kwargs):\n",
    "    \"\"\"fit log norm to data and plot the result\n",
    "\n",
    "    to be used with seaborn.FacetGrid.map_dataframe\n",
    "    \"\"\"\n",
    "    data = kwargs.pop('data')\n",
    "    color = kwargs.pop('color')\n",
    "    lines = []\n",
    "    # we want to collapse hemispheres -- eventually this should be moved earlier\n",
    "    tmp = pd.DataFrame(data.groupby([x, 'bootstrap_num'])[y].mean()).reset_index()\n",
    "    for boot in data.bootstrap_num.unique():\n",
    "        plot_data = tmp.groupby(x)[[y, 'bootstrap_num']].apply(lambda x, j: x[x.bootstrap_num==j], boot)\n",
    "        plot_idx = plot_data.index.get_level_values(x)\n",
    "        plot_vals = plot_data[y].values\n",
    "        try:\n",
    "            popt, _ = sp.optimize.curve_fit(sfp.utils.log_norm_pdf, plot_idx, plot_vals)\n",
    "        except RuntimeError:\n",
    "            warnings.warn(\"For eccentricity %s and frequency space %s, bootstrap %d was not well fit by a log Gaussian and so is skipped\" % (data['Eccentricity (degrees)'].unique()[0], data['Frequency'].unique()[0], boot))\n",
    "        else:\n",
    "            lines.append(sfp.utils.log_norm_pdf(plot_idx, *popt))\n",
    "    lines = np.array(lines)\n",
    "    lines_mean = lines.mean(0)\n",
    "    cis = np.percentile(lines, ci_vals, 0)\n",
    "    sns.plt.fill_between(plot_idx, cis[0], cis[1], facecolor=color, alpha=.2, **kwargs)\n",
    "    sns.plt.plot(plot_idx, lines_mean, color=color, **kwargs)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_hypotheses(df, axis_imgs=None, **kwargs):\n",
    "    \"\"\"\n",
    "    axis_imgs should be a 2d list / array containing 2-tuples. each tuple should contain the relative position of each\n",
    "        image and the corresponding image to put on an axis. the first dimension corresponds to the first axis, the second\n",
    "        to the second axis\n",
    "    \"\"\"\n",
    "    tmp_df = df[df.stimulus_superclass=='circular']\n",
    "#    tmp_df = tmp_df[['eccen', 'amplitude_estimate', 'freq_space_distance', 'Local spatial frequency (cpd)', 'bootstrap_num', 'hemi']]\n",
    "#    tmp_df = pd.melt(tmp_df, ['eccen', 'amplitude_estimate', 'bootstrap_num', 'hemi'], var_name='Frequency')\n",
    "    tmp_df = tmp_df[['eccen', 'amplitude_estimate', 'freq_space_distance', 'Local spatial frequency (cpd)', 'bootstrap_num',]]\n",
    "    tmp_df = pd.melt(tmp_df, ['eccen', 'amplitude_estimate', 'bootstrap_num',], var_name='Frequency')\n",
    "    tmp_df = tmp_df.rename(columns={'eccen': 'Eccentricity (degrees)'})\n",
    "\n",
    "    g = sns.FacetGrid(tmp_df, hue='Eccentricity (degrees)', row='Frequency',  palette='Reds', size=5, aspect=2, sharex=False,\n",
    "                      row_order=['Local spatial frequency (cpd)', 'freq_space_distance'])\n",
    "    #g.map_dataframe(sfp.utils.plot_mean, 'value', 'amplitude_estimate')\n",
    "    #g.map_dataframe(sfp.utils.scatter_ci_dist, 'value', 'amplitude_estimate', [50, 50])\n",
    "    g.map_dataframe(fit_log_norm_ci, 'value', 'amplitude_estimate', ci_vals=[16, 84])\n",
    "    g.map(sns.regplot, 'value', 'amplitude_estimate', x_estimator=np.mean, fit_reg=False, ci=0)\n",
    "    sns.plt.subplots_adjust(hspace=.6)\n",
    "    for i, ax in enumerate(g.axes.flatten()):\n",
    "        if i==1:\n",
    "            ax.set_title('Response as function of stimulus')\n",
    "        elif i==0:\n",
    "            ax.set_xlim([2**-3.5, 2**4])\n",
    "            ax.set_title('Response as function of local spatial frequency (cycles / degree)')\n",
    "        ax.set_xscale('log', basex=2)\n",
    "        for pos, img in axis_imgs[i]:\n",
    "            sfp.utils.add_img_to_xaxis(g.fig, ax, img, pos, vmin=0, vmax=255, size=.15)\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.set_ylabel(\"Response amplitude estimate\")\n",
    "    #g.ax.set_xlim([2**-3, 2**3.5])\n",
    "    g.add_legend()\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context('poster'), sns.axes_style('white'):\n",
    "    g = compare_hypotheses(df, [zip([.025, .6], stim_windows), zip([.05, .6], stims)])\n",
    "    g.savefig('SF-wl_subj045-results.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmper_df = tmp_df[['Local spatial frequency (cpd)', 'amplitude_estimate', 'eccen']]\n",
    "\n",
    "def fit_lnorm(data):\n",
    "    popt, pcov = sp.optimize.curve_fit(sfp.utils.log_norm_pdf, data.index, data.values)\n",
    "    return sfp.utils.log_norm_pdf(data.index, *popt), popt\n",
    "\n",
    "\n",
    "bandwidth = []\n",
    "peak = []\n",
    "for n, g in tmper_df.groupby('eccen'):\n",
    "    mn_data = g.groupby(['Local spatial frequency (cpd)'])['amplitude_estimate'].mean()\n",
    "    fit_data, params = fit_lnorm(mn_data)\n",
    "    peak.append([n, mn_data.index[np.argmax(fit_data.values)]])\n",
    "    bandwidth.append([n, np.exp(params[2])])\n",
    "\n",
    "peak = np.array([((int(i[0])+int(i[2]))/2., j) for i,j in peak])\n",
    "bandwidth = np.array([((int(i[0])+int(i[2]))/2., j) for i,j in bandwidth])\n",
    "print peak\n",
    "print bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plt.scatter(bandwidth[:,0], bandwidth[:,1], c=sns.color_palette('Reds', 6), s=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperbola(x, a):\n",
    "    b = 1.\n",
    "    period = x*a\n",
    "    period[x<b] = a*b\n",
    "    return 1./period\n",
    "\n",
    "def fit_hyperbola(peak):\n",
    "    popt, pcov = sp.optimize.curve_fit(hyperbola, peak[:,0], peak[:,1])\n",
    "    return popt\n",
    "\n",
    "opt_a = fit_hyperbola(peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_01 = peak\n",
    "opt_a_01 = opt_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecc = np.linspace(.01, 9, 50)\n",
    "RF_scale_factor = 4.\n",
    "V1_RF_size = np.concatenate([np.ones(len(ecc[ecc<.5]))/RF_scale_factor, np.linspace(1/RF_scale_factor, 4/RF_scale_factor, len(ecc[ecc>=.5]))])\n",
    "#V2_RF_size = np.concatenate([2*np.ones(len(ecc[ecc<4])), np.linspace(2, 2.5, len(ecc[ecc>=4]))])\n",
    "\n",
    "Olsson_peak = [2.75, 2.11, 1.76, 1.47,1.24, 1.06, .88, .77, .66, .60]\n",
    "Olsson_ecc = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "with sns.plotting_context('poster', font_scale=1), sns.axes_style('white'):\n",
    "    # because this doesn't represent data, just intuition, we use this.\n",
    "#    with plt.xkcd():\n",
    "    x = np.linspace(.01, 9, 50)\n",
    "    y = []\n",
    "    fig, axes = sns.plt.subplots(1,1, figsize=(13,6))\n",
    "    ax = axes\n",
    "    # this gives intuitive plots, currently we want the possible hypotheses instead\n",
    "#         for i in range(3):\n",
    "#             y.append(10/(x+2)+i)\n",
    "#             ax.plot(x, y[-1],  label='V%s'%(i+1), color=['r','g','b'][i])\n",
    "    colors = sns.color_palette(n_colors=3)\n",
    "    for i, (p, o) in enumerate([[peak_01, opt_a_01], [peak_42, opt_a_42], [peak_45, opt_a_45]]):\n",
    "#    ax.plot(ecc, hyperbola(ecc, opt_a), '-', label='scaling')\n",
    "#        ax.plot(ecc, hyperbola(ecc, o), '-', label='scaling', c= colors[i])\n",
    "        ax.plot(ecc, hyperbola(ecc, o), '-', label='Subject %s'%(i+1), c= colors[i])\n",
    "#    ax.plot(ecc, np.ones(len(ecc))*RF_scale_factor, '--', label='constant')\n",
    "#        ax.set_ylim((0,8))\n",
    "#    sns.plt.scatter(peak[:, 0], peak[:, 1], c=sns.color_palette('Reds', 6), s=75,)# label='This study')\n",
    "        if i==1:\n",
    "            sns.plt.scatter(p[:, 0]+.07, p[:, 1], c=colors[i], s=75,)# label='This study')\n",
    "        else:\n",
    "            sns.plt.scatter(p[:, 0], p[:, 1], c=colors[i], s=75,)# label='This study')\n",
    "#    sns.plt.scatter(Olsson_ecc, Olsson_peak, s=75, c= sns.color_palette('Blues', 10), label='Olsson pilot')\n",
    "    ax.set_xlabel(\"Receptive field center eccentricity (degrees)\")\n",
    "    ax.set_ylabel(\"Peak spatial frequency (cpd)\")\n",
    "    ax.set_title(\"\")\n",
    "    ax.set_ylim((.5, 4.5))\n",
    "    ax.set_xlim((0, 11))\n",
    "\n",
    "    sns.plt.legend(title=\"Subjects\", loc='best')\n",
    "    ax.figure.savefig('results-hypotheses.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double-check design matrix\n",
    "\n",
    "In order to use this, run everything except for the `sfp.experiment.run` statement first, which will create pictures, one from each class, in the order the `design_df` thinks they are presented. Then run the `sfp.experiment.run` block on a two-monitor setup so one monitor can display the experiment while you have this notebook open in the other. This will allow you to make sure the stimuli are being ordered correctly.\n",
    "\n",
    "You can also compare `design_df.index.values` to a picture of the design matrix to make sure things got transferred correctly there as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import sfp\n",
    "import h5py\n",
    "import os\n",
    "import pyPyrTools.JBhelpers as jbh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains the button presses (which also show the TR onsets) \n",
    "# and the order the stimuli were presented in (along with their timing)\n",
    "behav_results = h5py.File('../data/raw_behavioral/2017-Aug-23_Noah_sess1.hdf5')\n",
    "\n",
    "# This contains the information on each stimulus, allowing us to determine whether\n",
    "# some stimuli are part of the same class or a separate one.\n",
    "stim_df = pd.read_csv(\"../data/stimuli/unshuffled_stim_description.csv\", index_col=0)\n",
    "\n",
    "# Array full of the actual stimuli\n",
    "stim = np.load('../data/stimuli/unshuffled.npy')\n",
    "\n",
    "# for this, we just want any run, since they all contain the same classes and we don't care about their order\n",
    "design_df, stim_length, TR = sfp.first_level_analysis.create_design_df(behav_results, stim_df, 1, drop_blanks=False)\n",
    "design_df = design_df.reset_index(drop=True).set_index(\"class_idx\")\n",
    "\n",
    "stim_df['class_idx'] = np.floor(stim_df['index']/8)\n",
    "stim_df = stim_df.set_index('class_idx')\n",
    "stim_df['Onset time (TR)'] = design_df['Onset time (TR)']\n",
    "stim_df = stim_df.reset_index().sort('Onset time (TR)')\n",
    "\n",
    "stim_df = stim_df.drop_duplicates('class_idx')\n",
    "stim_idx = stim_df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sfp.experiment.run('../data/stimuli/unshuffled.npy', '../data/stimuli/Noah_run01_idx.npy', None, screen=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[:10]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[10:20]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[20:30]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[30:40]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[40:50]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[50:60]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[60:]], ncols=5, zoom=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
