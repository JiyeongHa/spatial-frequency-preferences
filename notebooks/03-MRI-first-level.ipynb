{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook the first level MRI analyses: setting up and examining a General Linear Model that produces response amplitudes for each stimulus class. For this, the data must be preprocessed. We will use GLMdenoise to do this, which is a MATLAB toolbox, and so the actual analysis will be run outside of this notebook (it takes a while and a lot of resources anyway, so this is for the best).\n",
    "\n",
    "# Creating the design matrix\n",
    "\n",
    "The first thing we need to do is create our design matrix. Our design matrix needs to be in the format time by conditions (where time is in TRs), with a 1 for condition onset. This will be exceedingly sparse, since each condition only shows up once per run (when we move this into matlab, we will make it a sparse matrix). We will have one of these design matrices per run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains the button presses (which also show the TR onsets) \n",
    "# and the order the stimuli were presented in (along with their timing)\n",
    "results = h5py.File('../data/raw_behavioral/2017-Aug-23_Noah_sess1.hdf5')\n",
    "\n",
    "# This contains the information on each stimulus, allowing us to determine whether\n",
    "# some stimuli are part of the same class or a separate one.\n",
    "df = pd.read_csv(\"../data/stimuli/unshuffled_stim_description.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backticks from the scanner are recorded as 5s, which we hold onto, allowing us to quickly see how many TRs we recorded in each run (the last run is empty because we quit it as soon as it started):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(9):\n",
    "    n_TRs = sum(['5' in i[0] for i in results['run_%02d_button_presses' % run].value])\n",
    "    print(\"Run %s: %s TRs\" % (run, n_TRs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have the onset times of all of our stimuli, as well as an identifying index we can use to look up its information. We know that we presented stimuli in classes, each of which contains 8 stimuli, but we can reconstruct that information by using the indices to look into the dataframe we loaded in.\n",
    "\n",
    "Based on how we constructed our stimuli, two stimuli belong to the same class iff they have the same `w_a` and `w_r` (angular and radial frequency) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = df[['w_r', 'w_a', 'index']].set_index('index')\n",
    "reduced_df = reduced_df.reindex(results['run_01_shuffled_indices'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by examining this reordered dataframe, our classes occur in batches of 8 (note that there are some that have `NaN`s for both values; these are the blank stimuli)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to discover this programmatically is to find the smallest amount we have to jump by such that each subsequent entry has a different `w_r` and a different `w_a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = 0\n",
    "break_out = False\n",
    "while ~break_out:\n",
    "    class_size += 1\n",
    "    w_r = reduced_df['w_r'].values.copy()\n",
    "    w_a = reduced_df['w_a'].values.copy()\n",
    "    # we replace the NaNs with zeros for this calculation -- we want them be different than all\n",
    "    # the other classes (and technically, the blank stimuli do have 0s in both w_r and w_a)\n",
    "    nan_replace = 0\n",
    "    w_r[np.isnan(w_r)] = nan_replace\n",
    "    w_a[np.isnan(w_a)] = nan_replace\n",
    "    tmp = np.abs(w_r[:-class_size:class_size] - w_r[class_size::class_size]) + np.abs(w_a[:-class_size:class_size] - w_a[class_size::class_size])\n",
    "    class_changes = np.nonzero(tmp)[0]\n",
    "    indices = np.array(range(len(tmp)))\n",
    "    if len(class_changes) == len(indices):\n",
    "        break_out = np.equal(class_changes, indices).all()\n",
    "print(\"Each class is of size %s\" % class_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know what the class index of each stimulus is then, which we can find by dividing the index by the number of stimuli in each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df['class_idx'] = reduced_df.index/class_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to figure out what TR each stimulus was presented during. We have the time (in seconds) they appeared on screen recorded, so we want to add that information to our dataframe. In order to do so, we will first subtract off the time of the first TR (so we now have the \"time of presentation from first TR\") and throw out a bit of extra information. We also recorded when the start screen was turned off (that's the first entry) and there are a final number of blank stimuli, which we'll throw away as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing = results['run_01_timing_data'].value\n",
    "# Because we want to skip the first one and drop the last nblanks * 2 (since for each stimuli\n",
    "# we have two entries: one for on, one for off). Finally, we only grab every other because we\n",
    "# only want the on timing\n",
    "timing = timing[1:-results['run_01_nblanks'].value*2:2]\n",
    "\n",
    "# Now we get rid of the first TR\n",
    "initial_TR_time = float(results['run_01_button_presses'].value[0][1])\n",
    "timing = [float(i[2]) - initial_TR_time for i in timing]\n",
    "\n",
    "# and add to our dataframe\n",
    "reduced_df['Onset time (sec)'] = timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply look for where there's a class transition, which happens every `class_size` (8) stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_df = reduced_df[::class_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert these to to TR times. First we find the onset times of TRs, in seconds, relative to the first TR. We then create a giant matrix where each row is a different stimulus onset time and then, in each column, subtract a TR onset time (so this matrix will be `num_conditions x num_TRs`). If we then round this difference-in-time matrix and look for the 0s, we've found what TR onset is closest to the onset of the stimuli. Note that this won't make sense for a lot of entries; some of them start almost exactly halfway through a TR. But, because of how we defined our experiment, our class transitions should happen right around a TR onset (if the timings of the scanner and the stimulus computer were perfect, then they would be exactly the same; as it is they probably differ by a few milliseconds) and so this will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 indicates a backtick from the scanner\n",
    "TR_times = np.array([float(i[1]) for i in results['run_01_button_presses'].value if '5'==i[0]])\n",
    "TR_times -= TR_times[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times = design_df['Onset time (sec)'].values\n",
    "stim_times = np.expand_dims(stim_times,1)\n",
    "stim_times = np.repeat(stim_times,len(TR_times),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_from_TR = np.round(stim_times - TR_times)\n",
    "design_df['Onset time (TR)'] = np.where(time_from_TR==0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we create our design matrix, iterate through throw our `design_df` and put a one where each class shows up in a TR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our blanks show up as having nan values, and we don't want to model them in our GLM, so we drop them.\n",
    "design_df = design_df.dropna()\n",
    "# because the values are 0-indexed\n",
    "design_matrix = np.zeros((len(TR_times), design_df.class_idx.max()+1))\n",
    "\n",
    "for i, row in design_df.iterrows():\n",
    "    row = row.astype(int)\n",
    "    design_matrix[row['Onset time (TR)'], row['class_idx']] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure things work correctly, we look at our axis sums: each class (axis 1) should show up exactly once and each TR (axis 0) should have 0 or 1 classes in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Each entry represents one of our %d classes:\" % design_matrix.shape[1])\n",
    "print(design_matrix.sum(0))\n",
    "\n",
    "print(\"Each entry represents one of our %d TRs:\" % design_matrix.shape[0])\n",
    "print(design_matrix.sum(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can look at our design matrix for this run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.imshow(design_matrix, 'gray', aspect='auto',)\n",
    "plt.title(\"Design matrix for run 1\")\n",
    "plt.xlabel(\"events\")\n",
    "plt.ylabel(\"TRs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `sfp.first_level_analysis.design_matrix` does the above (without the visualizations and checks) and returns the resulting design matrix. The function `sfp.first_level_analysis.create_all_design_matrices` does this for multiple runs and saves them as `.mat` files so they can be read into matlab.\n",
    "\n",
    "Actually running the first-level analysis requires matlab and should be run on the cluster (see `matlab/runGLM.m` and `matlab/runGLM.sbatch`), since they require Kendrick Kay's [GLMdenoise](http://kendrickkay.net/GLMdenoise/) package and use a lot of memory. After you've finished getting the results, examined the $R^2$ values to make sure they make sense, and realigned them to the subject's freesurfer anatomy (using `sfp.realign`), then you're ready for the following section, where we analyze these results.\n",
    "\n",
    "# Analyzing the first-level results\n",
    "\n",
    "After running our GLM analysis, we have the estimated amplitude responses of each voxel to each image class. Along with Noah Benson's anatomical template / Bayesian model, we also have each voxel's visual area and location in the visual field (in terms of eccentricity and polar angle). By combining the information contained within them, along with the dataframe describing each stimulus class, we can construct our tuning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import sfp\n",
    "import h5py\n",
    "import os\n",
    "import itertools\n",
    "import pyPyrTools.JBhelpers as jbh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains the button presses (which also show the TR onsets) \n",
    "# and the order the stimuli were presented in (along with their timing)\n",
    "behav_results = h5py.File('../data/raw_behavioral/2017-Aug-23_Noah_sess1.hdf5')\n",
    "\n",
    "# This contains the information on each stimulus, allowing us to determine whether\n",
    "# some stimuli are part of the same class or a separate one.\n",
    "stim_df = pd.read_csv(\"../data/stimuli/unshuffled_stim_description.csv\", index_col=0)\n",
    "\n",
    "# Array full of the actual stimuli\n",
    "stim = np.load('../data/stimuli/unshuffled.npy')\n",
    "\n",
    "# for this, we just want any run, since they all contain the same classes and we don't care about their order\n",
    "design_df, _, _ = sfp.first_level_analysis.create_design_df(behav_results, stim_df, 1)\n",
    "design_df = design_df.reset_index(drop=True).sort(\"class_idx\")\n",
    "design_df = design_df[['w_r', 'w_a', 'class_idx']].set_index('class_idx')\n",
    "\n",
    "stim_df = stim_df.set_index(['w_r', 'w_a'])\n",
    "stim_df['class_idx'] = design_df.reset_index().set_index(['w_r', 'w_a'])['class_idx']\n",
    "stim_df = stim_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name = 'wl_subj042'\n",
    "benson_path = \"%s/%s/surf/{}.benson14_{}.mgz\" % (os.environ['SUBJECTS_DIR'], subject_name)\n",
    "results_path = \"/mnt/Acadia/Projects/spatial_frequency_preferences/%s/20170823_prisma_pilot/MRI_first_level/stim_class/results/{}-{}.mgz\" % subject_name\n",
    "benson_path = benson_path.replace('{}', '%s')\n",
    "results_path = results_path.replace('{}', '%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sfp.first_level_analysis.create_GLM_result_df(design_df, benson_path, results_path)\n",
    "df = sfp.first_level_analysis.round_freq_space_distance(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the different stimulus classes, as plotted in frequency space, colored by their superclass. These numbers are roughly log-spaced (doubling).\n",
    "\n",
    "PROBLEMS:\n",
    "- we have $w_r<0$ and we want $w_a<0$\n",
    "- we go from 4 to 128 for spirals instead of 6 to 181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df[df.voxel==0], hue='stimulus_superclass', size=5, aspect=1)\n",
    "g.map(sns.plt.scatter, 'w_a', 'w_r')\n",
    "g.add_legend()\n",
    "_=g.ax.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmin, Rmax = sfp.first_level_analysis.find_ecc_range_in_degrees(stim[0,:,:], 12)\n",
    "print(\"Inside radius of stimulus annulus: %.02f\" % Rmin)\n",
    "print(\"Outside radius of stimulus annulus: %.02f\" % Rmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we only want to look at those voxels that lie within V1 (don't care if left or right hemisphere) and whose pRF centers lie between eccentricities of 2 and 8 degrees (based on above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.varea==1)&(df.eccen<8)&(df.eccen>2)]\n",
    "df = df.sort_values('eccen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our analysis, we bin by eccentricity. We see that things are reasonably well distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eccen_bin(ecc):\n",
    "    for i in xrange(2,11):\n",
    "        if ecc < i:\n",
    "            return \"%s-%s\" % (i-1, i)\n",
    "\n",
    "df['eccen_bin'] = df.eccen.apply(eccen_bin)\n",
    "\n",
    "sns.countplot('eccen_bin', data=df, palette='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df[df.stimulus_superclass=='circular']\n",
    "g = sns.FacetGrid(df, hue='eccen_bin', palette='Reds', size=5,)\n",
    "g.map(sns.regplot, 'rounded_freq_space_distance', 'model_ampl_est', x_estimator=np.mean, fit_reg=False)\n",
    "g.map_dataframe(sfp.utils.plot_mean, 'rounded_freq_space_distance', 'model_ampl_est')\n",
    "#g.map_dataframe(sf.utils.scatter_ci, 'freq_space_distance', 'model_ampl_est', 'model_std_error')\n",
    "for ax in g.axes.flatten():\n",
    "    ax.set_xscale('log', basex=2)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, hue='eccen_bin', palette='Reds', size=5, col='stimulus_superclass', col_wrap=2,\n",
    "                  col_order=['circular', 'radial', 'forward spiral', 'reverse spiral', 'mixtures'])\n",
    "g.map(sns.regplot, 'freq_space_distance', 'model_ampl_est', x_estimator=np.mean, fit_reg=False)\n",
    "g.map_dataframe(sfp.utils.plot_mean, 'freq_space_distance', 'model_ampl_est')\n",
    "#g.map_dataframe(sfp.utils.scatter_ci, 'freq_space_distance', 'model_ampl_est', 'model_std_error')\n",
    "for ax in g.axes:\n",
    "    ax.set_xscale('log', basex=2)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_of_interest = []\n",
    "classes_of_interest.extend(df[(df.stimulus_superclass=='radial')&(df.base_freq==64)].stimulus_class.unique())\n",
    "classes_of_interest.extend(df[(df.stimulus_superclass=='circular')&(df.base_freq==11)].stimulus_class.unique())\n",
    "classes_of_interest.extend(df[(df.stimulus_superclass=='forward spiral')&(df.base_freq==16)].stimulus_class.unique())\n",
    "classes_of_interest.extend(df[(df.stimulus_superclass=='reverse spiral')&(df.base_freq==16)].stimulus_class.unique())\n",
    "classes_of_interest.append(df[df.stimulus_superclass=='mixtures'].stimulus_class.values[0])\n",
    "\n",
    "stim_idxs = stim_df[stim_df.class_idx.isin(classes_of_interest)].index.values[::8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i, :, :] for i in stim_idxs], ncols=4, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(df[df.stimulus_superclass=='mixtures'].freq_space_angle.unique())\n",
    "labels = np.round([(i/np.pi*12) for i in labels])\n",
    "labels = ['$\\\\frac{%s*\\\\pi}{12}$'%int(i) for i in labels]\n",
    "\n",
    "tmp_df = df[df.stimulus_superclass=='mixtures']\n",
    "g = sns.FacetGrid(tmp_df, hue='eccen_bin', palette='Reds', size=5)\n",
    "\n",
    "'freq_space_angle', 'model_ampl_est', 'eccen_bin', tmp_df, size=5, palette='Reds')\n",
    "_=g.ax.set_xticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, hue='eccen_bin', palette='Reds', size=5, col='stimulus_superclass', col_wrap=2,\n",
    "                  col_order=['circular', 'radial', 'forward spiral', 'reverse spiral', 'mixtures'])\n",
    "#g.map(sns.regplot, 'freq_space_distance', 'model_ampl_est', x_estimator=np.mean, fit_reg=False)\n",
    "#g.map_dataframe(sfp.utils.plot_mean, 'freq_space_distance', 'model_ampl_est')\n",
    "g.map_dataframe(sfp.utils.scatter_ci, 'freq_space_distance', 'model_ampl_est', 'model_std_error')\n",
    "for ax in g.axes:\n",
    "    ax.set_xscale('log', basex=2)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame(df.groupby(['eccen_bin', 'w_r', 'w_a']).model_ampl_est.mean()).reset_index()\n",
    "\n",
    "g = sns.FacetGrid(tmp_df, col='eccen_bin', col_wrap=4, size=5)\n",
    "cbar_ax = g.fig.add_axes([.92, .3, .02, .4])  # <-- Create a colorbar axes\n",
    "g.map(sfp.utils.scatter_heat, 'w_a', 'w_r', 'model_ampl_est', vmin=tmp_df['model_ampl_est'].min(), vmax=tmp_df['model_ampl_est'].max())\n",
    "sns.plt.colorbar(cax=cbar_ax)\n",
    "g.fig.subplots_adjust(right=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_df = pd.pivot_table(df, 'model_ampl_est', 'rounded_freq_space_distance', 'eccen_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = tmp_df.copy()\n",
    "for col in norm_df.columns:\n",
    "    norm_df[col] = norm_df[col] / norm_df[col].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(tmp_df).invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(norm_df).invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.R2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double-check design matrix\n",
    "\n",
    "In order to use this, run everything except for the `sfp.experiment.run` statement first, which will create pictures, one from each class, in the order the `design_df` thinks they are presented. Then run the `sfp.experiment.run` block on a two-monitor setup so one monitor can display the experiment while you have this notebook open in the other. This will allow you to make sure the stimuli are being ordered correctly.\n",
    "\n",
    "You can also compare `design_df.index.values` to a picture of the design matrix to make sure things got transferred correctly there as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import sfp\n",
    "import h5py\n",
    "import os\n",
    "import pyPyrTools.JBhelpers as jbh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains the button presses (which also show the TR onsets) \n",
    "# and the order the stimuli were presented in (along with their timing)\n",
    "behav_results = h5py.File('../data/raw_behavioral/2017-Aug-23_Noah_sess1.hdf5')\n",
    "\n",
    "# This contains the information on each stimulus, allowing us to determine whether\n",
    "# some stimuli are part of the same class or a separate one.\n",
    "stim_df = pd.read_csv(\"../data/stimuli/unshuffled_stim_description.csv\", index_col=0)\n",
    "\n",
    "# Array full of the actual stimuli\n",
    "stim = np.load('../data/stimuli/unshuffled.npy')\n",
    "\n",
    "# for this, we just want any run, since they all contain the same classes and we don't care about their order\n",
    "design_df, stim_length, TR = sfp.first_level_analysis.create_design_df(behav_results, stim_df, 1, drop_blanks=False)\n",
    "design_df = design_df.reset_index(drop=True).set_index(\"class_idx\")\n",
    "\n",
    "stim_df['class_idx'] = np.floor(stim_df['index']/8)\n",
    "stim_df = stim_df.set_index('class_idx')\n",
    "stim_df['Onset time (TR)'] = design_df['Onset time (TR)']\n",
    "stim_df = stim_df.reset_index().sort('Onset time (TR)')\n",
    "\n",
    "stim_df = stim_df.drop_duplicates('class_idx')\n",
    "stim_idx = stim_df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sfp.experiment.run('../data/stimuli/unshuffled.npy', '../data/stimuli/Noah_run01_idx.npy', None, screen=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[:10]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[10:20]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[20:30]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[30:40]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[40:50]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[50:60]], ncols=5, zoom=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbh.showIm([stim[i,:,:] for i in stim_idx[60:]], ncols=5, zoom=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
